\section{Axiomatic models}

Our models are phrased in terms of \emph{events} (e.g. reads and writes), and
relations over these events (e.g. program order, read-from \dots). Formally,
our models are said to be \emph{axiomatic}. We give here a brief presentation
of axiomatic models in general. The expert reader might want to skip this
section.

Axiomatic models are usually defined in three stages. First, \emph{instruction
semantics} map each instruction to some mathematical objects. This allows us to
define the \emph{control-flow semantics} of a multi-threaded program.  Second,
we build a set of \emph{candidate executions} from this control-flow semantics:
each candidate execution represents one particular data-flow of the program,
i.e. which \emph{communications} might happen between the different threads of
our program. Third, a \emph{constraint specification} decides which candidate
executions are valid or not.

We now explain these concepts in a way that we hope to be intuitive. 
%We give the constraint specification part of our model in
%Section~\ref{sec:model}, and an outline of the instruction semantics in
%Section~\ref{sec:instr-sem}.

\subsection{Multi-threaded programs}

Multi-threaded programs, such as the one given in Figure~\ref{fig:mp-prog}, give
one sequence of \emph{instructions} per thread.  Instructions can come from a
given assembly language instruction set, or be pseudo-code instructions, as is
the case in Figure~\ref{fig:mp-prog}.

\begin{figure}[!h]
\begin{center}
\begin{tabularx}{.35\linewidth}{Y|Y}
\multicolumn{4}{c}{\textsf{mp}} \\ \midrule
\multicolumn{4}{l}{initially \as{x=0; \as{y=0}}}\\ \midrule
\multicolumn{2}{c|}{\haut\myth{0}} &
\multicolumn{2}{c}{\haut\myth{1}} \\ \midrule
\haut\instab{\pstore{1}{x}}{(a)} & \instab{\pload{r1}{y}}{(c)} \\
\bas\instab{\pstore{1}{y}}{(b)} & \instab{\pload{r2}{x}}{(d)}
\end{tabularx}
\end{center}
\caption{A multi-threaded program implementing a message passing
pattern\label{fig:mp-prog}} \end{figure}

In Figure~\ref{fig:mp-prog}, we have two threads \myth{0} and \myth{1} in
parallel. These two threads communicate via the two memory locations $x$ and
$y$, which hold the value $0$ initially. On \myth{0} we have a store of value
$1$ into memory location $x$, followed in program order by a store of value $1$
into memory location $y$. On \myth{1} we have a load of the contents of memory
location $y$ into register $r_1$, followed in program order by a load of the
contents of memory location $x$ into register $r_2$. Memory locations, \eg $x$
and $y$, are shared by the two threads, whereas the registers are private to
the thread holding them, here \myth{1}.

The snippet in Figure~\ref{fig:mp-prog} is at the heart of a message
passing (\textsf{mp}) pattern, where \myth{0} would write some data into memory
location $x$, then set a flag in $y$. \myth{1} would then check if it has the
flag, then read the data in $x$.

\subsection{Control-flow semantics}
The instruction semantics, in our case, translates instructions into
\emph{events}, which represent e.g. \emph{memory or register accesses} (i.e.
reads and writes from and to memory or registers), \emph{branching decisions}
or \emph{fences}.

\begin{figure}[!h]
\begin{center}
\newfmt{mp-cf}
\end{center}
\caption{Control-flow semantics for the message passing pattern of Figure~\ref{fig:mp-prog}\label{fig:mp-cf}}
\end{figure}

Consider Figure~\ref{fig:mp-cf}: we give a possible control-flow semantics to
the program in Figure~\ref{fig:mp-prog}. To do so, we proceed as follows: each
store instruction, \eg \pstore{1}{x} on \myth{0}, corresponds to a write event
specifying a memory location and a value, \eg Wx=1. Each load instruction, \eg
\pload{r1}{y} on \myth{1} corresponds to a read event specifying a memory
location and a undetermined value, \eg Ry=?.  Note that the memory locations of
the events are determined by the program text, as well as the values of the
writes. For reads, the values will be determined in the next stage.

Additionally, we also have implicit write events Wx=0 and Wy=0 representing the
initial state of $x$ and $y$ that we do not depict here.

The instruction semantics also defines \emph{relations} over these events,
representing for example the \emph{program order} within a thread, or
\emph{address, data or control dependencies} from one memory access to the
other, via computations over register values.

Thus in Figure~\ref{fig:mp-cf}, we also give the program order relation, written
\po{}, which lifts the order in which instructions have been written to the
level of events. For example, the two stores on \myth{0} in
Figure~\ref{fig:mp-prog} have been written in program order, thus their
corresponding events Wx=1 and Wy=1 are related by \po{} in
Figure~\ref{fig:mp-cf}.

We are now at a stage where we have, given a program such as the one in
Figure~\ref{fig:mp-prog}, several \emph{event graphs}, such as the one in
Figure~\ref{fig:mp-cf}. Each graph gives a set of events representing accesses
to memory and registers, the program order between these events, including
branching decisions, and the dependencies.

\subsection{Data-flow semantics}
The purpose of introducing data flow is to define which \emph{communications},
or \emph{interferences}, might happen between the different threads of our
program. To do so, we need to define two relations over memory events: the
\emph{read-from} relation \rf{}, and the \emph{coherence order} \co{}.

\begin{figure}[!h]
\begin{center}
\begin{tabular}{cc}
\newfmt{mp-df1} & \newfmt{mp-df3} \\
\newfmt{mp-df2} & \newfmt{mp-df4}
\end{tabular}
\end{center}
\caption{One possible data-flow semantics for the control-flow semantics given in Figure~\ref{fig:mp-cf}\label{fig:mp-df}}
\end{figure}

The read-from relation \rf{} describes, for any given read, from which write
this read could have taken its value. A read-from arrow with no source, as in
the top left of Figure~\ref{fig:mp-df}, corresponds to reading from the initial
state.

For example in Figure~\ref{fig:mp-df}, consider the drawing at the bottom
left-most corner. The read $c$ from $y$ takes its value from the initial state,
hence reads the value $0$. The read $d$ from $x$ takes its value from the
update $a$ of $x$ by \myth{0}, hence reads the value $1$.

The coherence order gives the order in which all the memory writes to a given
location have hit that location in memory. For example in
Figure~\ref{fig:mp-df}, the initial write to $x$ (not depicted) hits the memory
before the write $a$ on \myth{0}, by convention, hence the two writes are
ordered in coherence.

We are now at a stage where we have, given a program such as the one in
Figure~\ref{fig:mp-prog}, an event graph as given by the control-flow semantics
(see Figure~\ref{fig:mp-cf}), and several read-from relations and coherence
orders describing possible communications across threads (see
Figure~\ref{fig:mp-df}). In Figure~\ref{fig:mp-df}, we do not display any
coherence order, because there is only one write per location.

Note that for a given control-flow semantics there could be several suitable
data-flow semantics, if for example there were several writes to $x$ with value
$1$ in our example: in that case there would be two possible read-from to give
a value to the read of $x$ on~\myth{1}.

Each such object (see Figure~\ref{fig:mp-df}), which gathers events, program
order, dependencies, read-from and coherence, is called a \emph{candidate
execution}.  As one can see in Figure~\ref{fig:mp-df}, there can be more than
one candidate execution for a given program.

\subsection{Constraint specification} For each candidate execution, the
constraint specification part of our model decides whether this candidate
represents a valid execution or not.

Traditionally, such specifications are in terms of acyclicity or irreflexivity
of various combinations of the relations over events given by the candidate
execution. This means for example that the model would reject a candidate
execution if this candidate contains a cycle amongst a certain relation defined
in the constraint specification.

For example in Figure~\ref{fig:mp-df}, the constraints for describing Lamport's
Sequential Consistency~\cite{lam79} would rule out the right top-most candidate
execution because the read from $x$ on \myth{1} reads from the initial state,
whereas the read of $y$ on \myth{1} has observed the update of $y$ by \myth{0}.
